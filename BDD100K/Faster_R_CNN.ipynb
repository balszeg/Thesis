{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster R-CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfCwwRM1JgMUF/fnfxjMDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balszeg/Thesis/blob/main/Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4lGKojwQpNv"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rpE6EF8RWj8"
      },
      "source": [
        "Important to set the Colab runtime type to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1kwVr6EQcDg"
      },
      "source": [
        "# clone TensorFlow models repository\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7jO3KCCQzH0"
      },
      "source": [
        "# installing the necessary libraries, packages\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22eMKk-NQ-ru"
      },
      "source": [
        "# with the newest TensorFlow 2.5 the model cannot utilize GPU\n",
        "# hence it is recommended to downgrade it to the last stable version\n",
        "!pip install tensorflow==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiEV-LzJRXVh"
      },
      "source": [
        "# this script check if everything was installed correctly\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIh9YA65Rhwm"
      },
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwha7J3XRlsk"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4lh-iI5RoXs"
      },
      "source": [
        "# create directories for the data\n",
        "!mkdir /content/dataset\n",
        "!mkdir /content/dataset/train/\n",
        "!mkdir /content/dataset/train/annos/\n",
        "!mkdir /content/dataset/val/\n",
        "!mkdir /content/dataset/val/annos/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IddBX0oxR0Pm"
      },
      "source": [
        "# copy the original BDD100K dataset from drive\n",
        "!cp /content/gdrive/MyDrive/bdd100k/bdd100k_images.zip /content/dataset/\n",
        "!cp /content/gdrive/MyDrive/bdd100k/bdd100k_labels_release.zip /content/dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC3EMN4JR3eA"
      },
      "source": [
        "# unzip it\n",
        "%cd /content/dataset\n",
        "!unzip bdd100k_images.zip\n",
        "!unzip bdd100k_labels_release.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVzCBrZ-SDhv"
      },
      "source": [
        "# clone Monk Object Detection repository for .tfrecord converter\n",
        "%cd /content/\n",
        "!git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHANbI0vSMix"
      },
      "source": [
        "# the conversion order is the following: \n",
        "# BDD100K(.jpg, .txt)->Pascal VOC(.jpg, .xml)->TensorFlow (.record/.tfrecord)\n",
        "# install Pascal VOC writer\n",
        "!pip install pascal-voc-writer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDHgjJAFS0Ub"
      },
      "source": [
        "# set directories for training set\n",
        "img_dir = \"/content/dataset/bdd100k/images/100k/train/\"\n",
        "anno_file = \"/content/dataset/bdd100k/labels/bdd100k_labels_images_train.json\"\n",
        "output_dir = \"/content/dataset/train/annos\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efWuriUOS95X"
      },
      "source": [
        "# parse through the training label .json\n",
        "import json\n",
        "with open(anno_file) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_894IiZTDh3"
      },
      "source": [
        "# convert it to .xml files\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    name = data[i][\"name\"];\n",
        "    labels = data[i][\"labels\"];\n",
        "    #print(img_dir + \"/\" + name)\n",
        "    img = cv2.imread(img_dir + \"/\" + name);\n",
        "    h, w, c = img.shape;\n",
        "    writer = Writer(name, w, h)\n",
        "    for j in range(len(labels)):\n",
        "        obj = labels[j];\n",
        "        if(\"box2d\" in obj.keys()):\n",
        "            category = obj[\"category\"];\n",
        "            x1 = int(obj[\"box2d\"][\"x1\"]);\n",
        "            y1 = int(obj[\"box2d\"][\"y1\"]);\n",
        "            x2 = int(obj[\"box2d\"][\"x2\"]);\n",
        "            y2 = int(obj[\"box2d\"][\"y2\"]);\n",
        "            writer.addObject(category, x1, y1, x2, y2);\n",
        "    \n",
        "    writer.save(output_dir + \"/\" + name.split(\".\")[0] + \".xml\")\n",
        "\n",
        "        \n",
        "    #break;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oDxRJ4yUHXb"
      },
      "source": [
        "# creat labelmap.txt with classes\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "classes = [];\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    name = data[i][\"name\"];\n",
        "    labels = data[i][\"labels\"];\n",
        "    for j in range(len(labels)):\n",
        "        obj = labels[j];\n",
        "        if(\"box2d\" in obj.keys()):\n",
        "            category = obj[\"category\"];\n",
        "            if(category not in classes):\n",
        "                classes.append(category)\n",
        "\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxdSXOEQUIM3"
      },
      "source": [
        "f = open(\"classes.txt\", 'w');\n",
        "for i in range(len(classes)):\n",
        "    f.write(classes[i] + \"\\n\");\n",
        "f.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHFrLZLKTfZy"
      },
      "source": [
        "# set directories for validation set\n",
        "img_dir = \"/content/dataset/bdd100k/images/100k/val\";\n",
        "anno_file = \"/content/dataset/bdd100k/labels/bdd100k_labels_images_val.json\";\n",
        "output_dir = \"/content/dataset/val/annos\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV-BaSqGThUd"
      },
      "source": [
        "# parse through the validation label .json\n",
        "import json\n",
        "with open(anno_file) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMEw6vB6Tio5"
      },
      "source": [
        "# convert it to .xml files\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    name = data[i][\"name\"];\n",
        "    labels = data[i][\"labels\"];\n",
        "    #print(img_dir + \"/\" + name)\n",
        "    img = cv2.imread(img_dir + \"/\" + name);\n",
        "    h, w, c = img.shape;\n",
        "    writer = Writer(name, w, h)\n",
        "    for j in range(len(labels)):\n",
        "        obj = labels[j];\n",
        "        if(\"box2d\" in obj.keys()):\n",
        "            category = obj[\"category\"];\n",
        "            x1 = int(obj[\"box2d\"][\"x1\"]);\n",
        "            y1 = int(obj[\"box2d\"][\"y1\"]);\n",
        "            x2 = int(obj[\"box2d\"][\"x2\"]);\n",
        "            y2 = int(obj[\"box2d\"][\"y2\"]);\n",
        "            writer.addObject(category, x1, y1, x2, y2);\n",
        "    \n",
        "    writer.save(output_dir + \"/\" + name.split(\".\")[0] + \".xml\")\n",
        "\n",
        "        \n",
        "    #break;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98D4baHCT1P3"
      },
      "source": [
        "# import libraries for .record creations\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/13_tf_obj_2/lib/\")\n",
        "\n",
        "from train_detector import Detector\n",
        "gtf = Detector();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCPhv9WaUdCA"
      },
      "source": [
        "# set up the path for the training data\n",
        "train_img_dir = \"/content/dataset/bdd100k/images/100k/train/\";\n",
        "train_anno_dir = \"/content/dataset/train/annos\";\n",
        "class_list_file = \"classes.txt\";\n",
        "\n",
        "gtf.set_train_dataset(train_img_dir, train_anno_dir, class_list_file, batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0G7hMWkUty6"
      },
      "source": [
        "# same set up with validation set\n",
        "val_img_dir = \"/content/dataset/bdd100k/images/100k/val/\";\n",
        "val_anno_dir = \"/content/dataset/val/annos\";\n",
        "\n",
        "gtf.set_val_dataset(val_img_dir, val_anno_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2-eJieTU2rf"
      },
      "source": [
        "# creat both set in .record form\n",
        "gtf.create_tfrecord(data_output_dir=\"data_tfrecord\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPoK606-U7r8"
      },
      "source": [
        "## TensorBoard setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlCGCwQPVG3Y"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/models/research/object_detection/training/train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKFs-GSFV6rZ"
      },
      "source": [
        "If this won't open it for some reason, there is an alternative way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTEGqebDV2ZK"
      },
      "source": [
        "%cd /content/\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgue_jGNWDlg"
      },
      "source": [
        "LOG_DIR = \"/content/models/research/object_detection/training/train/\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1z_wnDfWFzo"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7A1Obr_WHQO"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgpaLT_MWMRj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3dF8yrvWWQ5"
      },
      "source": [
        "# download the official config, if training for the first time\n",
        "%cd /content/models/research/object_detection\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xvf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRohsxcdWeAp"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "!mkdir training\n",
        "!cp /content/models/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config /content/models/research/object_detection/training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fg5J_YwWQqZ"
      },
      "source": [
        "!python model_main_tf2.py --pipeline_config_path=training/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config --model_dir=training --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N5agphfXJnS"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2iDQa6TXLZ3"
      },
      "source": [
        "# export the trained model for later inference\n",
        "!python exporter_main_v2.py --trained_checkpoint_dir training --output_directory inference_graph --pipeline_config_path training/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raO50CQhXR_n"
      },
      "source": [
        "# calculate the metrics\n",
        "!python model_main_tf2.py --pipeline_config_path=training/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config --model_dir=training --checkpoint_dir=training --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du7RCn_fYCmY"
      },
      "source": [
        "# for video inference, an another git repository needed\n",
        "%cd /content\n",
        "!git clone https://github.com/alen-smajic/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir45pZZqYNb4"
      },
      "source": [
        "# testing on a video\n",
        "%cd /content/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/Faster R-CNN\n",
        "!python3 detect_objects.py --model_path /content/inference_graph/saved_model --path_to_labelmap /content/vodeo/labelmap.txt --video_input --video_path /content/vodeo/selfmade.mp4 --save_output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
