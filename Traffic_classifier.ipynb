{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9zTke5N4ssjTJYn8hwyyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balszeg/Thesis/blob/main/Traffic_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuhqdTJNVs-2"
      },
      "source": [
        "## Data collection and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC3KEPgAV1XO"
      },
      "source": [
        "# clone the OIDv4 Toolkit\n",
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGDsjuicV4R9"
      },
      "source": [
        "# install it\n",
        "%cd /content/OIDv4_ToolKit/\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK3pcyF4V6gg"
      },
      "source": [
        "# collect the train set\n",
        "!python3 main.py downloader -y --classes Car Van Truck Motorcycle --type_csv train --limit 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO5UjGpdV9uY"
      },
      "source": [
        "# collect the validation set\n",
        "!python3 main.py downloader -y --classes Car Van Truck Motorcycle --type_csv validation --limit 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8qPfuabpq64"
      },
      "source": [
        "# collect the test set\n",
        "!python3 main.py downloader -y --classes Car Van Truck Motorcycle --type_csv test --limit 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMHyhSFFXCKV"
      },
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6LUY0NdUKi"
      },
      "source": [
        "# set the data path\n",
        "base_dir = '/content/OIDv4_ToolKit/OID/Dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "train_car_dir = os.path.join(train_dir, 'Car')\n",
        "train_van_dir = os.path.join(train_dir, 'Van')\n",
        "train_truck_dir = os.path.join(train_dir, 'Truck')\n",
        "train_motorcyc_dir = os.path.join(train_dir, 'Motorcycle')\n",
        "train_car_fnames = os.listdir(train_car_dir)\n",
        "train_van_fnames = os.listdir(train_van_dir)\n",
        "train_truck_fnames = os.listdir(train_truck_dir)\n",
        "train_motorcyc_fnames = os.listdir(train_motorcyc_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPXI0i-Th24O"
      },
      "source": [
        "# examine a few images from the set\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "next_car_pix = [os.path.join(train_car_dir, fname) for fname in train_car_fnames[:int(ncols*nrows/2)]]\n",
        "next_van_pix = [os.path.join(train_van_dir, fname) for fname in train_van_fnames[:int(ncols*nrows/2)]]\n",
        "next_truck_pix = [os.path.join(train_truck_dir, fname) for fname in train_truck_fnames[:int(ncols*nrows/2)]]\n",
        "next_motorcyc_pix = [os.path.join(train_motorcyc_dir, fname) for fname in train_motorcyc_fnames[:int(ncols*nrows/2)]]\n",
        "\n",
        "for i, img_path in enumerate(next_car_pix+next_van_pix+next_truck_pix+next_motorcyc_pix):\n",
        "    sp = plt.subplot(nrows, ncols, i + 1)\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHsC77igXIhV"
      },
      "source": [
        "# setup the labels \n",
        "labels = ['Car', 'Van', 'Truck','Motorcycle']\n",
        "img_size = 224\n",
        "\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "          try:\n",
        "               img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
        "               resized_arr = cv2.resize(img_arr,(img_size, img_size)) # Reshaping images to preferred size\n",
        "               data.append([resized_arr, class_num])\n",
        "          except Exception as e:\n",
        "               print(e)\n",
        "    return np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrb4ac48XWJG"
      },
      "source": [
        "# arrange the datasets\n",
        "train = get_data('/content/OIDv4_ToolKit/OID/Dataset/train/')\n",
        "val = get_data('/content/OIDv4_ToolKit/OID/Dataset/validation/')\n",
        "test = get_data('/content/OIDv4_ToolKit/OID/Dataset/test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9szTx4Ie2rl"
      },
      "source": [
        "# check train set distribution\n",
        "l = []\n",
        "for i in train:\n",
        "    if(i[1] == 0):\n",
        "        l.append(\"Car\")\n",
        "    if(i[1] == 1):\n",
        "        l.append(\"Van\")\n",
        "    if(i[1] == 2):\n",
        "        l.append(\"Truck\")\n",
        "    if(i[1] == 3):\n",
        "        l.append(\"Motorcycle\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMtJcA5_fQvJ"
      },
      "source": [
        "# check validation set distribution\n",
        "k = []\n",
        "for i in val:\n",
        "    if(i[1] == 0):\n",
        "        k.append(\"Car\")\n",
        "    if(i[1] == 1):\n",
        "        k.append(\"Van\")\n",
        "    if(i[1] == 2):\n",
        "        k.append(\"Truck\")\n",
        "    if(i[1] == 3):\n",
        "        k.append(\"Motorcycle\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPBe4JItpaH"
      },
      "source": [
        "# check test set distribution\n",
        "m = []\n",
        "for i in test:\n",
        "    if(i[1] == 0):\n",
        "        m.append(\"Car\")\n",
        "    if(i[1] == 1):\n",
        "        m.append(\"Van\")\n",
        "    if(i[1] == 2):\n",
        "        m.append(\"Truck\")\n",
        "    if(i[1] == 3):\n",
        "        m.append(\"Motorcycle\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiQVoKt_foXi"
      },
      "source": [
        "# setup the sets for modifications\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_test.append(feature)\n",
        "  y_test.append(label)\n",
        "\n",
        "# normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255\n",
        "\n",
        "# reshape them to model sufficient sizes\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad8bowhDfuZc"
      },
      "source": [
        "# use datagenerator for augmenting\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYWN520oamIS"
      },
      "source": [
        "## Self-designed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrEi7F-Ifzd6"
      },
      "source": [
        "# build up the self-designed model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlSV0ghRf31k"
      },
      "source": [
        "# configure the learning parameters\n",
        "opt = Adam(lr=0.000001) #SGD(lr=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n",
        "checkpointer=ModelCheckpoint(filepath='HandMade.h5',save_best_only=True,verbose=1,)\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzeezGqbgBAM"
      },
      "source": [
        "# start training\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs = 500, validation_data = (x_val, y_val), shuffle=True, callbacks=[checkpointer,earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnChAsdgVGa"
      },
      "source": [
        "# draw training graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(90) # early stoppingnál figyelni kell rá\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_icBdbOhh-JB"
      },
      "source": [
        "# calculate metrics\n",
        "predictions = model.predict_classes(x_val)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "print(classification_report(y_val, predictions, target_names = ['Car (Class 0)','Van (Class 1)', 'Truck (Class 2)', 'Motorcycle (Class 3)']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJw6AICnbAsR"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE1DCVcSpAad"
      },
      "source": [
        "# download VGG16\n",
        "baseModel = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_tensor=tf.keras.layers.Input(shape=(224, 224, 3)))\n",
        "output = baseModel.output\n",
        "# removing the outlayers and change it to own\n",
        "output = tf.keras.layers.GlobalAveragePooling2D()(output)\n",
        "output = tf.keras.layers.Dense(1024, activation=\"relu\")(output)\n",
        "output = tf.keras.layers.Dense(4, activation='softmax')(output)\n",
        "model = tf.keras.Model(inputs=baseModel.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxYiyK7OpQe3"
      },
      "source": [
        "# transfer learning:\n",
        "# compile the model, with froze base model making the training only on the new top layers\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzngxKBhwQpG"
      },
      "source": [
        "# start the train\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)\n",
        "checkpointer = ModelCheckpoint(filepath='VGG16.h5',save_best_only=True,verbose=1)\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=500, verbose=1,validation_data=(x_val, y_val), shuffle = True,callbacks=[earlystopping,checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtOMwXZAwzgd"
      },
      "source": [
        "# draw training graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(178) # the epoch number of range changes according to earlystop\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuA2oLjGf3ST"
      },
      "source": [
        "# calculate graph\n",
        "predictions = model.predict(x_val)\n",
        "predictions2 = np.argmax(predictions,axis=1)\n",
        "print(classification_report(y_val, predictions2, target_names = ['Car (Class 0)','Van (Class 1)', 'Truck (Class 2)', 'Motorcycle (Class 3)']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF8F-H4w_Myv"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIC2Wppj-kUW"
      },
      "source": [
        "# freeze the trained top layers and unfreeze the base model for training\n",
        "for layer in model.layers[:15]:\n",
        "       layer.trainable = False\n",
        "for layer in model.layers[15:]:\n",
        "       layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePAJ1ahf-9lf"
      },
      "source": [
        "# start the training\n",
        "checkpointer=ModelCheckpoint(filepath='VGG16_unfrost.h5',save_best_only=True,verbose=1)\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=500, verbose=1,validation_data=(x_val, y_val), shuffle = True,callbacks=[checkpointer,earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGnRxrE-t1DD"
      },
      "source": [
        "# draw graphs for the improvement due to transfer learning\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(31) # the epoch number of range changes according to earlystop\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzRjXXyUhRqx"
      },
      "source": [
        "# calculate metrics\n",
        "predictions = model.predict(x_val)\n",
        "predictions2 = np.argmax(predictions,axis=1)\n",
        "print(classification_report(y_val, predictions2, target_names = ['Car (Class 0)','Van (Class 1)', 'Truck (Class 2)', 'Motorcycle (Class 3)']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}